{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250555ca",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48e922",
   "metadata": {},
   "source": [
    "## 1. Initial Setup\n",
    "\n",
    "- Set variables and hyperparameters\n",
    "- Import libraries\n",
    "- Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d55102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max allowable epochs for each model type\n",
    "MAX_EPOCHS = 2000\n",
    "\n",
    "# Hyperparameters for Hyperparameter Optimization using Optuna\n",
    "OPTUNA_N_JOBS = 8                   # Number of parallel jobs for hyperparameter optimization - controls how many trials run simultaneously\n",
    "OPTUNA_N_TRIALS = 40                # Total number of optimization trials to run - more trials generally lead to better hyperparameter discovery\n",
    "OPTUNA_PRUNE_N_STARTUP_TRIALS = 8   # Number of random trials before pruning starts - ensures diverse exploration before early stopping\n",
    "OPTUNA_PRUNE_WARMUP_STEPS = 8       # Number of steps to wait before pruning can occur - prevents premature termination of promising trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = \"../data/ANA HIDROWEB/RIO MEIA PONTE/processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python native libraries\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import os\n",
    "import warnings\n",
    "import uuid\n",
    "\n",
    "# Data manipulation and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PyTorch libraries and derivatives\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchinfo import summary\n",
    "\n",
    "# Optuna Libraries\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "# Set precision for matrix multiplication in order to optimize performance\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    PROCESSED_PATH,\n",
    "    sep=\";\",\n",
    "    parse_dates=[\"date\"],\n",
    "    dayfirst=True,\n",
    ")\n",
    "\n",
    "df.set_index(\"date\", inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20efaa67",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "- Conferir ausência de dados nulos\n",
    "- Retirar as colunas de vazão, uma vez que está altamente correlacionada à coluna de nível\n",
    "- Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58024d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "def print_missing_values(data):\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "print_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns containing 'flow' from the dataframe\n",
    "df = df.loc[:, ~df.columns.str.contains('flow')]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a422e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_normalized = pd.DataFrame(\n",
    "    scaler.fit_transform(df),\n",
    "    index=df.index,\n",
    "    columns=df.columns\n",
    ")\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc430dee",
   "metadata": {},
   "source": [
    "## 3. Criação dos Datasets\n",
    "\n",
    "- Criar dataset para série temporal\n",
    "- Dividir o dataset em treino, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length=24, target_col=\"level_downstream_max\"):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_col = self.data.columns.get_loc(target_col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx : idx + self.sequence_length].values  # (sequence_length, num_features)\n",
    "        y = self.data.iloc[idx + self.sequence_length, self.target_col] # scalar value\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class NonOverlappingConcatDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "        self.cumulative_lengths = []\n",
    "        total = 0\n",
    "        for d in datasets:\n",
    "            self.cumulative_lengths.append(total)\n",
    "            total += len(d)\n",
    "        self.total_length = total\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find which dataset this idx belongs to\n",
    "        for i in range(len(self.datasets)):\n",
    "            if idx < self.cumulative_lengths[i] + len(self.datasets[i]):\n",
    "                local_idx = idx - self.cumulative_lengths[i]\n",
    "                return self.datasets[i][local_idx]\n",
    "        raise IndexError(\"Index out of range\")\n",
    "\n",
    "\n",
    "def split_train_validation_test(\n",
    "    data: pd.DataFrame, train_size: float = 0.8, val_size: float = 0.1\n",
    "):\n",
    "    train_end = int(len(data) * train_size)\n",
    "    val_end = int(len(data) * (train_size + val_size))\n",
    "\n",
    "    train_data = data.iloc[:train_end]\n",
    "    val_data = data.iloc[train_end:val_end]\n",
    "    test_data = data.iloc[val_end:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "def create_datasets(\n",
    "    sequence_length: int,\n",
    ") -> Tuple[\n",
    "    NonOverlappingConcatDataset,\n",
    "    NonOverlappingConcatDataset,\n",
    "    NonOverlappingConcatDataset,\n",
    "]:\n",
    "    datasets_train: List[TimeSeriesDataset] = []\n",
    "    datasets_validation: List[TimeSeriesDataset] = []\n",
    "    datasets_test: List[TimeSeriesDataset] = []\n",
    "    for year in range(2010, 2024):\n",
    "        year_data = df_normalized[df_normalized.index.year == year].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        if not year_data.empty:\n",
    "            train_data, validation_data, test_data = split_train_validation_test(\n",
    "                year_data\n",
    "            )\n",
    "            datasets_train.append(\n",
    "                TimeSeriesDataset(train_data, sequence_length=sequence_length)\n",
    "            )\n",
    "            datasets_validation.append(\n",
    "                TimeSeriesDataset(validation_data, sequence_length=sequence_length)\n",
    "            )\n",
    "            datasets_test.append(\n",
    "                TimeSeriesDataset(test_data, sequence_length=sequence_length)\n",
    "            )\n",
    "\n",
    "    train_dataset = NonOverlappingConcatDataset(datasets_train)\n",
    "    validation_dataset = NonOverlappingConcatDataset(datasets_validation)\n",
    "    test_dataset = NonOverlappingConcatDataset(datasets_test)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "# Debugging example\n",
    "# fake_train, fake_validation, fake_test = create_datasets(\n",
    "#     sequence_length=2,\n",
    "# )  # Example with sequence length of 2\n",
    "\n",
    "# print(fake_train[0][1])\n",
    "# fake_train[0][0].shape, fake_train[0][1].shape  # Should be (2, num_features), scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for TimeSeriesDataset\n",
    "\n",
    "# Create a simple DataFrame with increasing integers\n",
    "test_df = pd.DataFrame({'A': np.arange(10)})\n",
    "\n",
    "# Window length = 3\n",
    "ts_dataset = TimeSeriesDataset(test_df, sequence_length=3, target_col='A')\n",
    "\n",
    "print(\"Testing TimeSeriesDataset:\")\n",
    "for i in range(len(ts_dataset)):\n",
    "    x, y = ts_dataset[i]\n",
    "    print(f\"Index {i}: x = {x.squeeze().numpy()}, y = {y.numpy()}\")\n",
    "\n",
    "# Test for NonOverlappingConcatDataset\n",
    "# Create two small TimeSeriesDatasets\n",
    "df1 = pd.DataFrame({'A': np.arange(5)})\n",
    "df2 = pd.DataFrame({'A': np.arange(10, 15)})\n",
    "\n",
    "ds1 = TimeSeriesDataset(df1, sequence_length=2, target_col='A')\n",
    "ds2 = TimeSeriesDataset(df2, sequence_length=2, target_col='A')\n",
    "\n",
    "concat_ds = NonOverlappingConcatDataset([ds1, ds2])\n",
    "\n",
    "print(\"\\nTesting NonOverlappingConcatDataset\")\n",
    "print(\"Should not overlap and should concatenate correctly:\")\n",
    "for i in range(len(concat_ds)):\n",
    "    x, y = concat_ds[i]\n",
    "    print(f\"Index {i}: x = {x.squeeze().numpy()}, y = {y.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba9bb9",
   "metadata": {},
   "source": [
    "## 4. Definição dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c514fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # MLP para cada passo temporal\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(in_features, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_features = hidden_size\n",
    "        self.step_mlp = nn.Sequential(*layers)\n",
    "        self.final_layer = nn.Linear(in_features, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, window_length, input_size)\n",
    "        # Aplica o MLP em cada passo temporal    print(\"x type:\", type(x))\n",
    "        batch, window, features = x.shape\n",
    "        x = x.view(-1, features)  # (batch * window_length, input_size)\n",
    "        out = self.step_mlp(x)  # (batch * window_length, hidden)\n",
    "        out = out.view(batch, window, -1)  # (batch, window_length, hidden)\n",
    "        out = out.mean(dim=1)  # (batch, hidden) - agregação temporal\n",
    "        out = self.final_layer(out)  # (batch, input_size)\n",
    "        return out.squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # (batch, sequence_length, hidden_size)\n",
    "        return self.fc(out[:, -1, :]).squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class GRU(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(GRU, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "print(summary(MLP(input_size=5, hidden_layers=[10, 10])))\n",
    "print(\"\\n\")\n",
    "print(summary(LSTM(input_size=5, hidden_size=10, num_layers=2)))\n",
    "print(\"\\n\")\n",
    "print(summary(GRU(input_size=5, hidden_size=10, num_layers=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a37da",
   "metadata": {},
   "source": [
    "## 5. Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6571f6",
   "metadata": {},
   "source": [
    "### 5.1. training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a05212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    logger,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    callbacks=[],\n",
    "    verbose=True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Treina o modelo com os dados de treino e validação.\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        val_data, batch_size=4, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        logger=logger,\n",
    "        enable_progress_bar=verbose,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=callbacks,\n",
    "        deterministic=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        enable_model_summary=verbose,\n",
    "    )\n",
    "    trainer.fit(model, train_loader, validation_loader)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, logger, batch_size=4):\n",
    "    \"\"\"\n",
    "    Avalia o modelo com os dados de teste.\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating model. Using the test dataset.\")\n",
    "    test_loader = DataLoader(\n",
    "        test_data, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        logger=logger,\n",
    "        enable_progress_bar=True,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    trainer.test(model, test_loader)\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    model_class: type[L.LightningModule],\n",
    "    name: str,\n",
    "    model_kwargs: Dict[str, Any] = {},\n",
    "    train_kwargs: Dict[str, Any] = {},\n",
    "    evaluate: bool = True,\n",
    "    extra_callbacks: List[L.Callback] = [],\n",
    "    verbose: bool = True,\n",
    "    id: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa um experimento de treinamento e avaliação do modelo.\n",
    "    \"\"\"\n",
    "    # Logger\n",
    "    logger = TensorBoardLogger(save_dir=os.getcwd(), name=f\"lightning_logs/{name}\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\", mode=\"min\", save_top_k=1, filename=f\"best_model_{id}\"\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-4,\n",
    "        patience=10,\n",
    "        mode=\"min\",\n",
    "        strict=False,\n",
    "    )\n",
    "\n",
    "    train_dataset, validation_dataset, test_dataset = create_datasets(\n",
    "        sequence_length=train_kwargs.get(\"sequence_length\", 5)\n",
    "    )\n",
    "\n",
    "    # Remove 'sequence_length' from train_kwargs if present\n",
    "    train_kwargs = dict(train_kwargs)  # make a copy to avoid side effects\n",
    "    train_kwargs.pop(\"sequence_length\", None)\n",
    "\n",
    "    input_size = train_dataset[0][0].shape[1]  # Assuming all inputs have the same shape\n",
    "\n",
    "    model = model_class(input_size=input_size, **(model_kwargs or {}))\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        validation_dataset,\n",
    "        logger=logger,\n",
    "        **(train_kwargs or {}),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, *extra_callbacks],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    best_validation_loss = checkpoint_callback.best_model_score\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "\n",
    "    # To view the logs, you can use TensorBoard.\n",
    "    # If 'logs' is a SummaryWriter, get its log_dir and launch TensorBoard:\n",
    "    print(f\"To view logs, run in terminal:\\n  tensorboard --logdir {logger.log_dir}\")\n",
    "    print(\"Best model saved at:\", best_model_path)\n",
    "\n",
    "    if evaluate:\n",
    "        best_model = model_class.load_from_checkpoint(best_model_path, **model_kwargs)\n",
    "        evaluate_model(best_model, test_dataset, logger, batch_size=4)\n",
    "\n",
    "    return {\n",
    "        \"best_validation_loss\": (\n",
    "            best_validation_loss.item() if best_validation_loss is not None else None\n",
    "        ),\n",
    "        \"best_model_path\": best_model_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f36313",
   "metadata": {},
   "source": [
    "### 5.2. Hyperparameter optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimization_args(model_class: L.LightningModule, trial):\n",
    "    \"\"\"\n",
    "    Retorna os argumentos necessários para executar o experimento.\n",
    "    \"\"\"\n",
    "    if model_class == MLP:\n",
    "        model_kwargs = {\n",
    "            \"hidden_layers\": trial.suggest_categorical(\n",
    "                \"hidden_layers\",\n",
    "                (\n",
    "                    [32, 16],\n",
    "                    [48, 24],\n",
    "                    [64, 32],\n",
    "                    [96, 48],\n",
    "                    [128, 64],\n",
    "                    [64, 32, 16],\n",
    "                    [128, 64, 32],\n",
    "                ),\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 2, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 2, 15),\n",
    "        }\n",
    "    elif model_class == LSTM:\n",
    "        model_kwargs = {\n",
    "            \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 128),\n",
    "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 2, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 2, 15),\n",
    "        }\n",
    "    elif model_class == GRU:\n",
    "        model_kwargs = {\n",
    "            \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 128),\n",
    "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 8, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 3, 12),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class}\")\n",
    "    return model_kwargs, train_kwargs\n",
    "\n",
    "\n",
    "def get_objective_fn(model_class, name):\n",
    "    \"\"\"\n",
    "    Retorna uma função de objetivo para otimização de hiperparâmetros.\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        # Ajusta os hiperparâmetros com base no trial\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            model_kwargs, train_kwargs = get_optimization_args(model_class, trial)\n",
    "\n",
    "        optuna_pruning_callback = PyTorchLightningPruningCallback(\n",
    "            trial, monitor=\"val_loss\"\n",
    "        )\n",
    "\n",
    "        results = run_experiment(\n",
    "            model_class=model_class,\n",
    "            name=name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            train_kwargs=train_kwargs,\n",
    "            evaluate=False,\n",
    "            extra_callbacks=[optuna_pruning_callback],\n",
    "            verbose=False,\n",
    "            id=uuid.uuid4().hex[:8],\n",
    "        )\n",
    "        return results[\"best_validation_loss\"]\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def run_optimization(objective_fn, n_trials=OPTUNA_N_TRIALS) -> optuna.study.Study:\n",
    "    pruner = optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=OPTUNA_PRUNE_N_STARTUP_TRIALS,\n",
    "        n_warmup_steps=OPTUNA_PRUNE_WARMUP_STEPS,\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "    study.optimize(\n",
    "        objective_fn, n_trials=n_trials, n_jobs=OPTUNA_N_JOBS, show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94945e1",
   "metadata": {},
   "source": [
    "### 5.3. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae341c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_objective_fn = get_objective_fn(\n",
    "    MLP,\n",
    "    \"mlp\",\n",
    ")\n",
    "\n",
    "study_mlp = run_optimization(mlp_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "\n",
    "mlp_optimized_results = run_experiment(\n",
    "    MLP,\n",
    "    \"mlp_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_layers\": study_mlp.best_trial.params[\"hidden_layers\"],\n",
    "        \"learning_rate\": study_mlp.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_mlp.best_trial.params[\"batch_size\"],\n",
    "        \"sequence_length\": study_mlp.best_trial.params[\"sequence_length\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\nMLP Optimized Results:\", mlp_optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_objective_fn = get_objective_fn(\n",
    "    LSTM,\n",
    "    \"lstm\",\n",
    ")\n",
    "study_lstm = run_optimization(lstm_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "lstm_optimized_results = run_experiment(\n",
    "    LSTM,\n",
    "    \"lstm_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_size\": study_lstm.best_trial.params[\"hidden_size\"],\n",
    "        \"num_layers\": study_lstm.best_trial.params[\"num_layers\"],\n",
    "        \"learning_rate\": study_lstm.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_lstm.best_trial.params[\"batch_size\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"\\nLSTM Optimized Results:\", lstm_optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_objective_fn = get_objective_fn(\n",
    "    GRU,\n",
    "    \"gru\",\n",
    ")\n",
    "study_gru = run_optimization(gru_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "gru_optimized_results = run_experiment(\n",
    "    GRU,\n",
    "    \"gru_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_size\": study_gru.best_trial.params[\"hidden_size\"],\n",
    "        \"num_layers\": study_gru.best_trial.params[\"num_layers\"],\n",
    "        \"learning_rate\": study_gru.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_gru.best_trial.params[\"batch_size\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    ")\n",
    "print(\"\\nGRU Optimized Results:\", gru_optimized_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
