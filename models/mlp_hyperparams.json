{
  "hidden_layers": [
    32,
    16
  ],
  "learning_rate": 0.0007068310524669469,
  "epochs": 50,
  "batch_size": 21,
  "model_type": "MLP",
  "sequence_length": 4,
  "input_size": 39
}