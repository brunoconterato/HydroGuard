{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250555ca",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Este notebook apresenta o pipeline completo de *Machine Learning* para previsão do nível do rio a partir de dados hidrológicos e meteorológicos. O objetivo é construir, treinar e avaliar modelos capazes de prever eventos críticos, como enchentes, utilizando séries temporais.\n",
    "\n",
    "> **Resumo das etapas:**\n",
    "> - Pré-processamento dos dados\n",
    "> - Criação de conjuntos de treino, validação e teste\n",
    "> - Definição e treinamento de modelos (MLP, LSTM, GRU)\n",
    "> - Otimização de hiperparâmetros\n",
    "> - Avaliação e visualização dos resultados\n",
    "> - Conclusão e próximos passos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db48e922",
   "metadata": {},
   "source": [
    "## 1. Initial Setup\n",
    "\n",
    "Esta seção realiza a configuração inicial do ambiente para o experimento de *Machine Learning*.\n",
    "\n",
    "- **Definição de variáveis e hiperparâmetros:** Estabelece limites e parâmetros para o treinamento dos modelos, como número máximo de épocas e configurações do Optuna.\n",
    "- **Importação de bibliotecas:** Carrega todas as dependências necessárias para manipulação de dados, visualização, modelagem e otimização.\n",
    "- **Carregamento do dataset:** Importa os dados já pré-processados, prontos para uso nos modelos.\n",
    "\n",
    "> *Certifique-se de que todas as bibliotecas estejam instaladas e que o dataset esteja disponível no caminho especificado.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d55102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max allowable epochs for each model type\n",
    "MAX_EPOCHS = 2000\n",
    "\n",
    "# Hyperparameters for Hyperparameter Optimization using Optuna\n",
    "OPTUNA_N_JOBS = 8  # Number of parallel jobs for hyperparameter optimization - controls how many trials run simultaneously\n",
    "OPTUNA_N_TRIALS = 30  # Total number of optimization trials to run - more trials generally lead to better hyperparameter discovery\n",
    "OPTUNA_PRUNE_N_STARTUP_TRIALS = 8  # Number of random trials before pruning starts - ensures diverse exploration before early stopping\n",
    "OPTUNA_PRUNE_WARMUP_STEPS = 8  # Number of steps to wait before pruning can occur - prevents premature termination of promising trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python native libraries\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import warnings\n",
    "import uuid\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Data manipulation and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# PyTorch libraries and derivatives\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchinfo import summary\n",
    "\n",
    "# Optuna Libraries\n",
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "# Add the parent directory to the system path to import custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "db_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"db\"))\n",
    "if db_path not in sys.path:\n",
    "    sys.path.append(db_path)\n",
    "\n",
    "# Set precision for matrix multiplication in order to optimize performance\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_process import load_and_process_data_from_db\n",
    "\n",
    "df = load_and_process_data_from_db(start_date=\"2014-01-01\", end_date=\"2024-12-31\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20efaa67",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Esta etapa prepara os dados para o treinamento dos modelos, garantindo qualidade e consistência.\n",
    "\n",
    "- **Verificação de dados nulos:** Identifica e trata possíveis valores ausentes, evitando problemas durante o treinamento.\n",
    "- **Remoção de colunas de vazão:** Exclui variáveis altamente correlacionadas (como `flow`), reduzindo redundância e evitando *overfitting*.\n",
    "- **Normalização:** Aplica normalização para padronizar as escalas das variáveis, o que é fundamental para o bom desempenho de modelos baseados em gradiente.\n",
    "\n",
    "> *O pré-processamento é essencial para garantir que os modelos aprendam padrões reais e não ruídos ou vieses dos dados.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58024d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "def print_missing_values(data):\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "\n",
    "print_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns containing 'flow' from the dataframe\n",
    "df = df.loc[:, ~df.columns.str.contains(\"flow\")]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a422e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Normalize all columns except 'date_sin' and 'date_cos' (if present)\n",
    "cols_to_normalize = [col for col in df.columns if col not in [\"date_sin\", \"date_cos\"]]\n",
    "df_normalized = df.copy()\n",
    "df_normalized[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])\n",
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc430dee",
   "metadata": {},
   "source": [
    "## 3. Criação dos Datasets\n",
    "\n",
    "Aqui são definidos os conjuntos de dados para treino, validação e teste, utilizando uma abordagem de *chunking* aleatório.\n",
    "\n",
    "> *Essa estratégia melhora a generalização dos modelos e simula cenários reais de produção, onde padrões podem variar ao longo do tempo.*\n",
    "\n",
    "**Vantagens do chunking:**\n",
    "- Diversifica os contextos temporais em cada split\n",
    "- Reduz o risco de especialização em um único regime temporal\n",
    "- Mantém a dependência temporal essencial para séries temporais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7550b",
   "metadata": {},
   "source": [
    "**Sobre a divisão dos dados:**\n",
    "\n",
    "Neste projeto, utilizamos a divisão dos dados por *chunking* aleatório com split sequencial dentro de cada chunk, em vez do split sequencial tradicional. Veja abaixo a diferença entre as abordagens:\n",
    "\n",
    "- **Chunking aleatório + split sequencial (utilizado aqui):**\n",
    "  - Os dados são divididos em blocos (chunks) de tamanho aleatório.\n",
    "  - Cada chunk é separado sequencialmente em treino, validação e teste.\n",
    "  - Isso garante que cada split contenha diferentes padrões temporais, regimes e sazonalidades.\n",
    "\n",
    "- **Split sequencial tradicional:**\n",
    "  - Os dados são divididos em três blocos contínuos: início para treino, meio para validação e fim para teste.\n",
    "  - Eventos raros ou mudanças de regime podem ficar concentrados em apenas um split, dificultando a generalização.\n",
    "\n",
    "> **Neste projeto, utilizamos o método de chunking aleatório, pois ele proporciona maior diversidade e robustez na avaliação dos modelos.**\n",
    "\n",
    "**Vantagens de cada abordagem:**\n",
    "\n",
    "| Estratégia                   | Vantagens principais                                                                 |\n",
    "|------------------------------|-----------------------------------------------------------------------------------|\n",
    "| Chunking aleatório           | Diversidade de padrões em todos os splits, simula cenários reais, melhor generalização |\n",
    "| Split sequencial tradicional | Simples de implementar, reflete cenários de previsão futura, mas pode ser enviesado  |\n",
    "\n",
    "---\n",
    "\n",
    "**Visualização esquemática:**\n",
    "\n",
    "Split Sequencial Tradicional:\n",
    "\n",
    "Treino      | Validação | Teste\n",
    "------------|-----------|---------\n",
    "████████████|████████|████████\n",
    "\n",
    "Chunking Aleatório + Split Sequencial (utilizado):\n",
    "\n",
    "| Chunk 1 |   |   | Chunk 2 |   |   | ... |\n",
    "|--------------|--------------|--------------|--------------|--------------|--------------|------|\n",
    "| Treino | Validação | Teste | Treino | Validação | Teste | ... |\n",
    "|████████████|████████|████████|████████████|████████|████████| ... |\n",
    "\n",
    "Legenda: Cada 3 colunas representam um chunk, e dentro de cada chunk há blocos de treino, validação e teste (Treino | Validação | Teste).\n",
    "\n",
    "*No split tradicional, cada split é um bloco contínuo. No chunking, cada chunk contém amostras de treino, validação e teste, promovendo diversidade em todos os splits.*\n",
    "\n",
    "> *A escolha do chunking aleatório permite que o modelo aprenda e seja avaliado em diferentes contextos temporais, tornando-o mais robusto para aplicações reais.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length=24, target_col=\"level_downstream_max\"):\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.target_col = self.data.columns.get_loc(target_col)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[\n",
    "            idx : idx + self.sequence_length\n",
    "        ].values  # (sequence_length, num_features)\n",
    "        # Label is the value of target_col for the next day after the sequence\n",
    "        y = self.data.iloc[idx + self.sequence_length, self.target_col]  # next day\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(\n",
    "            y, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "\n",
    "class NonOverlappingConcatDataset(Dataset):\n",
    "    def __init__(self, datasets):\n",
    "        self.datasets = datasets\n",
    "        self.cumulative_lengths = []\n",
    "        total = 0\n",
    "        for d in datasets:\n",
    "            self.cumulative_lengths.append(total)\n",
    "            total += len(d)\n",
    "        self.total_length = total\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Find which dataset this idx belongs to\n",
    "        for i in range(len(self.datasets)):\n",
    "            if idx < self.cumulative_lengths[i] + len(self.datasets[i]):\n",
    "                local_idx = idx - self.cumulative_lengths[i]\n",
    "                return self.datasets[i][local_idx]\n",
    "        raise IndexError(\"Index out of range\")\n",
    "\n",
    "\n",
    "def split_train_validation_test(\n",
    "    data: pd.DataFrame, train_size: float = 0.6, val_size: float = 0.2\n",
    "):\n",
    "    train_end = int(len(data) * train_size)\n",
    "    val_end = int(len(data) * (train_size + val_size))\n",
    "\n",
    "    train_data = data.iloc[:train_end]\n",
    "    val_data = data.iloc[train_end:val_end]\n",
    "    test_data = data.iloc[val_end:]\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "\n",
    "def create_datasets(\n",
    "    sequence_length: int,\n",
    "    min_chunk_size: int = 24,\n",
    "    max_chunk_size: int = 100,\n",
    ") -> Tuple[\n",
    "    NonOverlappingConcatDataset,\n",
    "    NonOverlappingConcatDataset,\n",
    "    NonOverlappingConcatDataset,\n",
    "]:\n",
    "    import random\n",
    "\n",
    "    datasets_train: List[TimeSeriesDataset] = []\n",
    "    datasets_validation: List[TimeSeriesDataset] = []\n",
    "    datasets_test: List[TimeSeriesDataset] = []\n",
    "\n",
    "    data = df_normalized.reset_index(drop=True)\n",
    "    n = len(data)\n",
    "    idx = 0\n",
    "    chunk_indices = []\n",
    "\n",
    "    # Generate random chunk indices\n",
    "    while idx < n:\n",
    "        chunk_size = random.randint(min_chunk_size, max_chunk_size)\n",
    "        if idx + chunk_size >= n:\n",
    "            # Last chunk\n",
    "            if n - idx < min_chunk_size:\n",
    "                break  # Discard last chunk if too small\n",
    "            chunk_indices.append((idx, n))\n",
    "            break\n",
    "        else:\n",
    "            chunk_indices.append((idx, idx + chunk_size))\n",
    "            idx += chunk_size\n",
    "\n",
    "    for start, end in chunk_indices:\n",
    "        chunk = data.iloc[start:end].reset_index(drop=True)\n",
    "        if not chunk.empty:\n",
    "            train_data, validation_data, test_data = split_train_validation_test(chunk)\n",
    "            if (\n",
    "                len(train_data) > sequence_length\n",
    "                and len(validation_data) > sequence_length\n",
    "                and len(test_data) > sequence_length\n",
    "            ):\n",
    "                datasets_train.append(\n",
    "                    TimeSeriesDataset(train_data, sequence_length=sequence_length)\n",
    "                )\n",
    "                datasets_validation.append(\n",
    "                    TimeSeriesDataset(validation_data, sequence_length=sequence_length)\n",
    "                )\n",
    "                datasets_test.append(\n",
    "                    TimeSeriesDataset(test_data, sequence_length=sequence_length)\n",
    "                )\n",
    "\n",
    "    train_dataset = NonOverlappingConcatDataset(datasets_train)\n",
    "    validation_dataset = NonOverlappingConcatDataset(datasets_validation)\n",
    "    test_dataset = NonOverlappingConcatDataset(datasets_test)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "\n",
    "# Debugging example\n",
    "# fake_train, fake_validation, fake_test = create_datasets(\n",
    "#     sequence_length=2,\n",
    "# )  # Example with sequence length of 2\n",
    "\n",
    "# print(fake_train[0][1])\n",
    "# fake_train[0][0].shape, fake_train[0][1].shape  # Should be (2, num_features), scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for TimeSeriesDataset\n",
    "\n",
    "# Create a simple DataFrame with increasing integers\n",
    "test_df = pd.DataFrame({\"A\": np.arange(10)})\n",
    "\n",
    "# Window length = 3\n",
    "ts_dataset = TimeSeriesDataset(test_df, sequence_length=3, target_col=\"A\")\n",
    "\n",
    "print(\"Testing TimeSeriesDataset:\")\n",
    "for i in range(len(ts_dataset)):\n",
    "    x, y = ts_dataset[i]\n",
    "    print(f\"Index {i}: x = {x.squeeze().numpy()}, y = {y.numpy()}\")\n",
    "\n",
    "# Test for NonOverlappingConcatDataset\n",
    "# Create two small TimeSeriesDatasets\n",
    "df1 = pd.DataFrame({\"A\": np.arange(5)})\n",
    "df2 = pd.DataFrame({\"A\": np.arange(10, 15)})\n",
    "\n",
    "ds1 = TimeSeriesDataset(df1, sequence_length=2, target_col=\"A\")\n",
    "ds2 = TimeSeriesDataset(df2, sequence_length=2, target_col=\"A\")\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "\n",
    "concat_ds = NonOverlappingConcatDataset([ds1, ds2])\n",
    "\n",
    "print(\"\\nTesting NonOverlappingConcatDataset\")\n",
    "print(\"Should not overlap and should concatenate correctly:\")\n",
    "for i in range(len(concat_ds)):\n",
    "    x, y = concat_ds[i]\n",
    "    print(f\"Index {i}: x = {x.squeeze().numpy()}, y = {y.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba9bb9",
   "metadata": {},
   "source": [
    "## 4. Definição dos Modelos\n",
    "\n",
    "Nesta etapa são definidos os modelos de *Machine Learning* utilizados para previsão:\n",
    "\n",
    "- **MLP (Perceptron Multicamadas):** Modelo denso tradicional, útil como baseline para séries temporais.\n",
    "- **LSTM (Long Short-Term Memory):** Rede neural recorrente especializada em capturar dependências de longo prazo em séries temporais.\n",
    "- **GRU (Gated Recurrent Unit):** Variante mais simples e eficiente da LSTM, também indicada para séries temporais.\n",
    "\n",
    "Cada modelo é implementado utilizando o framework PyTorch Lightning, facilitando o treinamento, validação e integração com callbacks e loggers.\n",
    "\n",
    "> *A escolha de diferentes arquiteturas permite comparar desempenho e identificar a abordagem mais adequada para o problema.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c514fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(MLP, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # MLP para cada passo temporal\n",
    "        layers = []\n",
    "        in_features = input_size\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(in_features, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_features = hidden_size\n",
    "        self.step_mlp = nn.Sequential(*layers)\n",
    "        self.final_layer = nn.Linear(in_features, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, window_length, input_size)\n",
    "        # Aplica o MLP em cada passo temporal    print(\"x type:\", type(x))\n",
    "        batch, window, features = x.shape\n",
    "        x = x.view(-1, features)  # (batch * window_length, input_size)\n",
    "        out = self.step_mlp(x)  # (batch * window_length, hidden)\n",
    "        out = out.view(batch, window, -1)  # (batch, window_length, hidden)\n",
    "        out = out.mean(dim=1)  # (batch, hidden) - agregação temporal\n",
    "        out = self.final_layer(out)  # (batch, input_size)\n",
    "        return out.squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class LSTM(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # (batch, sequence_length, hidden_size)\n",
    "        return self.fc(out[:, -1, :]).squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class GRU(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        learning_rate: float = 0.0001,\n",
    "    ):\n",
    "        super(GRU, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out[:, -1, :]).squeeze(-1)  # (batch,)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "print(summary(MLP(input_size=5, hidden_layers=[10, 10])))\n",
    "print(\"\\n\")\n",
    "print(summary(LSTM(input_size=5, hidden_size=10, num_layers=2)))\n",
    "print(\"\\n\")\n",
    "print(summary(GRU(input_size=5, hidden_size=10, num_layers=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a37da",
   "metadata": {},
   "source": [
    "## 5. Treinamento dos Modelos\n",
    "\n",
    "Esta seção abrange todo o processo de treinamento, validação e otimização dos modelos.\n",
    "\n",
    "- **Funções de treinamento:** Automatizam o processo de treino, validação e avaliação dos modelos, utilizando *callbacks* para checkpoint e early stopping.\n",
    "- **Otimização de hiperparâmetros:** Utiliza o Optuna para encontrar as melhores configurações de cada modelo, acelerando o processo com paralelismo e pruning.\n",
    "- **Laço de treinamento:** Executa o treinamento final dos modelos com os melhores hiperparâmetros encontrados.\n",
    "\n",
    "> *O uso de automação e otimização garante experimentos reprodutíveis e eficientes.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6571f6",
   "metadata": {},
   "source": [
    "### 5.1. Funções de treinamento\n",
    "\n",
    "As funções desta subseção são responsáveis por:\n",
    "\n",
    "- Treinar os modelos com os dados de treino e validação\n",
    "- Avaliar o desempenho nos dados de teste\n",
    "- Gerenciar logs, checkpoints e callbacks\n",
    "\n",
    "> *Utilize estas funções para garantir um fluxo de treinamento padronizado e monitorado.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a05212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_data,\n",
    "    val_data,\n",
    "    logger,\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    callbacks=[],\n",
    "    verbose=True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Treina o modelo com os dados de treino e validação.\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "    )\n",
    "    validation_loader = DataLoader(\n",
    "        val_data, batch_size=4, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        logger=logger,\n",
    "        enable_progress_bar=verbose,\n",
    "        log_every_n_steps=1,\n",
    "        callbacks=callbacks,\n",
    "        deterministic=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        enable_model_summary=verbose,\n",
    "    )\n",
    "    trainer.fit(model, train_loader, validation_loader)\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_data, logger, batch_size=4):\n",
    "    \"\"\"\n",
    "    Avalia o modelo com os dados de teste.\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating model. Using the test dataset.\")\n",
    "    test_loader = DataLoader(\n",
    "        test_data, batch_size=batch_size, shuffle=False, drop_last=True\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        logger=logger,\n",
    "        enable_progress_bar=True,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    trainer.test(model, test_loader)\n",
    "\n",
    "\n",
    "def save_model_and_hyperparams(\n",
    "    model,\n",
    "    model_class,\n",
    "    model_kwargs,\n",
    "    train_kwargs,\n",
    "    input_size=None,\n",
    "    sequence_length=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save the model state dict and hyperparameters to the models/ directory.\n",
    "    Ensures sequence_length and input_size são sempre salvos como parte dos hiperparâmetros.\n",
    "    \"\"\"\n",
    "    model_type = model_class.__name__.lower()\n",
    "    models_dir = os.path.join(os.getcwd(), \"..\", \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    pt_path = os.path.join(models_dir, f\"{model_type}.pt\")\n",
    "    torch.save(model.state_dict(), pt_path)\n",
    "    hyperparams = dict(model_kwargs)\n",
    "    hyperparams.update(train_kwargs)\n",
    "    hyperparams[\"model_type\"] = model_class.__name__\n",
    "    # Always save sequence_length if provided\n",
    "    if sequence_length is not None:\n",
    "        hyperparams[\"sequence_length\"] = sequence_length\n",
    "    # Always save input_size\n",
    "    hyperparams[\"input_size\"] = input_size\n",
    "    json_path = os.path.join(models_dir, f\"{model_type}_hyperparams.json\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(hyperparams, f, indent=2)\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    model_class: type[L.LightningModule],\n",
    "    name: str,\n",
    "    model_kwargs: Dict[str, Any] = {},\n",
    "    train_kwargs: Dict[str, Any] = {},\n",
    "    evaluate: bool = True,\n",
    "    extra_callbacks: List[L.Callback] = [],\n",
    "    verbose: bool = True,\n",
    "    id: str = \"\",\n",
    "    save_path: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Executa um experimento de treinamento e avaliação do modelo.\n",
    "    \"\"\"\n",
    "    # Logger\n",
    "    logger = TensorBoardLogger(save_dir=os.getcwd(), name=f\"lightning_logs/{name}\")\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\", mode=\"min\", save_top_k=1, filename=f\"best_model_{id}\"\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-4,\n",
    "        patience=10,\n",
    "        mode=\"min\",\n",
    "        strict=False,\n",
    "    )\n",
    "\n",
    "    train_dataset, validation_dataset, test_dataset = create_datasets(\n",
    "        sequence_length=train_kwargs.get(\"sequence_length\", 5)\n",
    "    )\n",
    "\n",
    "    # Remove 'sequence_length' from train_kwargs if present\n",
    "    train_kwargs = dict(train_kwargs)  # make a copy to avoid side effects\n",
    "    sequence_length = train_kwargs.pop(\"sequence_length\", None)\n",
    "\n",
    "    input_size = train_dataset[0][0].shape[1]  # Assuming all inputs have the same shape\n",
    "\n",
    "    model = model_class(input_size=input_size, **(model_kwargs or {}))\n",
    "\n",
    "    train_model(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        validation_dataset,\n",
    "        logger=logger,\n",
    "        **(train_kwargs or {}),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, *extra_callbacks],\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    best_validation_loss = checkpoint_callback.best_model_score\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "\n",
    "    # To view the logs, you can use TensorBoard.\n",
    "    # If 'logs' is a SummaryWriter, get its log_dir and launch TensorBoard:\n",
    "    print(f\"To view logs, run in terminal:\\n  tensorboard --logdir {logger.log_dir}\")\n",
    "    print(\"Best model saved at:\", best_model_path)\n",
    "\n",
    "    if evaluate:\n",
    "        best_model = model_class.load_from_checkpoint(best_model_path, **model_kwargs)\n",
    "        evaluate_model(best_model, test_dataset, logger, batch_size=4)\n",
    "\n",
    "    if save_path:\n",
    "        save_model_and_hyperparams(\n",
    "            best_model,\n",
    "            model_class,\n",
    "            model_kwargs,\n",
    "            train_kwargs,\n",
    "            input_size=input_size,\n",
    "            sequence_length=sequence_length,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"best_validation_loss\": (\n",
    "            best_validation_loss.item() if best_validation_loss is not None else None\n",
    "        ),\n",
    "        \"best_model_path\": best_model_path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f36313",
   "metadata": {},
   "source": [
    "### 5.2. Funções de otimização de hiperparâmetros\n",
    "\n",
    "Esta subseção implementa a busca automática pelos melhores hiperparâmetros dos modelos utilizando o Optuna.\n",
    "\n",
    "- **Definição do espaço de busca:** Cada modelo possui um conjunto de hiperparâmetros a serem otimizados (ex: número de camadas, taxa de aprendizado, tamanho da janela temporal).\n",
    "- **Função objetivo:** Avalia o desempenho do modelo para cada combinação de hiperparâmetros.\n",
    "- **Execução dos experimentos:** Roda múltiplos experimentos em paralelo, utilizando pruning para acelerar a busca.\n",
    "\n",
    "> *A otimização de hiperparâmetros é fundamental para extrair o máximo desempenho dos modelos.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimization_args(model_class: L.LightningModule, trial):\n",
    "    \"\"\"\n",
    "    Retorna os argumentos necessários para executar o experimento.\n",
    "    \"\"\"\n",
    "    if model_class == MLP:\n",
    "        model_kwargs = {\n",
    "            \"hidden_layers\": trial.suggest_categorical(\n",
    "                \"hidden_layers\",\n",
    "                (\n",
    "                    [32, 16],\n",
    "                    [48, 24],\n",
    "                    [64, 32],\n",
    "                    [96, 48],\n",
    "                    [128, 64],\n",
    "                    [64, 32, 16],\n",
    "                    [128, 64, 32],\n",
    "                ),\n",
    "            ),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 2, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 2, 15),\n",
    "        }\n",
    "    elif model_class == LSTM:\n",
    "        model_kwargs = {\n",
    "            \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 128),\n",
    "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 2, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 2, 15),\n",
    "        }\n",
    "    elif model_class == GRU:\n",
    "        model_kwargs = {\n",
    "            \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 128),\n",
    "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-7, 1e-3, log=True),\n",
    "        }\n",
    "        train_kwargs = {\n",
    "            \"epochs\": MAX_EPOCHS,\n",
    "            \"batch_size\": trial.suggest_int(\"batch_size\", 8, 32),\n",
    "            \"sequence_length\": trial.suggest_int(\"sequence_length\", 3, 12),\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model class: {model_class}\")\n",
    "    return model_kwargs, train_kwargs\n",
    "\n",
    "\n",
    "def get_objective_fn(model_class, name):\n",
    "    \"\"\"\n",
    "    Retorna uma função de objetivo para otimização de hiperparâmetros.\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        # Ajusta os hiperparâmetros com base no trial\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "            model_kwargs, train_kwargs = get_optimization_args(model_class, trial)\n",
    "\n",
    "        optuna_pruning_callback = PyTorchLightningPruningCallback(\n",
    "            trial, monitor=\"val_loss\"\n",
    "        )\n",
    "\n",
    "        results = run_experiment(\n",
    "            model_class=model_class,\n",
    "            name=name,\n",
    "            model_kwargs=model_kwargs,\n",
    "            train_kwargs=train_kwargs,\n",
    "            evaluate=False,\n",
    "            extra_callbacks=[optuna_pruning_callback],\n",
    "            verbose=False,\n",
    "            id=uuid.uuid4().hex[:8],\n",
    "        )\n",
    "        return results[\"best_validation_loss\"]\n",
    "\n",
    "    return objective\n",
    "\n",
    "\n",
    "def run_optimization(objective_fn, n_trials=OPTUNA_N_TRIALS) -> optuna.study.Study:\n",
    "    pruner = optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=OPTUNA_PRUNE_N_STARTUP_TRIALS,\n",
    "        n_warmup_steps=OPTUNA_PRUNE_WARMUP_STEPS,\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "    study.optimize(\n",
    "        objective_fn, n_trials=n_trials, n_jobs=OPTUNA_N_JOBS, show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94945e1",
   "metadata": {},
   "source": [
    "### 5.3. Laço de treinamento final\n",
    "\n",
    "Aqui são executados os treinamentos finais dos modelos MLP, LSTM e GRU utilizando os melhores hiperparâmetros encontrados na etapa anterior.\n",
    "\n",
    "- **Treinamento final:** Cada modelo é treinado do zero com os hiperparâmetros otimizados.\n",
    "- **Avaliação:** O desempenho é avaliado nos dados de teste, permitindo comparação justa entre as arquiteturas.\n",
    "\n",
    "> *Os resultados obtidos aqui servirão de base para análise e conclusões posteriores.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae341c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_objective_fn = get_objective_fn(\n",
    "    MLP,\n",
    "    \"mlp\",\n",
    ")\n",
    "\n",
    "study_mlp = run_optimization(mlp_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "\n",
    "mlp_optimized_results = run_experiment(\n",
    "    MLP,\n",
    "    \"mlp_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_layers\": study_mlp.best_trial.params[\"hidden_layers\"],\n",
    "        \"learning_rate\": study_mlp.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_mlp.best_trial.params[\"batch_size\"],\n",
    "        \"sequence_length\": study_mlp.best_trial.params[\"sequence_length\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    "    save_path=\"../models/mlp_optimized.pt\",\n",
    ")\n",
    "print(\"\\nMLP Optimized Results:\", mlp_optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_objective_fn = get_objective_fn(\n",
    "    LSTM,\n",
    "    \"lstm\",\n",
    ")\n",
    "study_lstm = run_optimization(lstm_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "lstm_optimized_results = run_experiment(\n",
    "    LSTM,\n",
    "    \"lstm_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_size\": study_lstm.best_trial.params[\"hidden_size\"],\n",
    "        \"num_layers\": study_lstm.best_trial.params[\"num_layers\"],\n",
    "        \"learning_rate\": study_lstm.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_lstm.best_trial.params[\"batch_size\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    "    save_path=\"../models/lstm_optimized.pt\",\n",
    ")\n",
    "print(\"\\nLSTM Optimized Results:\", lstm_optimized_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_objective_fn = get_objective_fn(\n",
    "    GRU,\n",
    "    \"gru\",\n",
    ")\n",
    "study_gru = run_optimization(gru_objective_fn, n_trials=OPTUNA_N_TRIALS)\n",
    "gru_optimized_results = run_experiment(\n",
    "    GRU,\n",
    "    \"gru_optimized\",\n",
    "    model_kwargs={\n",
    "        \"hidden_size\": study_gru.best_trial.params[\"hidden_size\"],\n",
    "        \"num_layers\": study_gru.best_trial.params[\"num_layers\"],\n",
    "        \"learning_rate\": study_gru.best_trial.params[\"learning_rate\"],\n",
    "    },\n",
    "    train_kwargs={\n",
    "        \"epochs\": MAX_EPOCHS,\n",
    "        \"batch_size\": study_gru.best_trial.params[\"batch_size\"],\n",
    "    },\n",
    "    evaluate=True,\n",
    "    verbose=True,\n",
    "    save_path=\"../models/gru_optimized.pt\",\n",
    ")\n",
    "print(\"\\nGRU Optimized Results:\", gru_optimized_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e2199",
   "metadata": {},
   "source": [
    "## 6. Avaliação dos Modelos\n",
    "\n",
    "Esta etapa compara o desempenho dos modelos treinados, utilizando métricas quantitativas e visualizações gráficas.\n",
    "\n",
    "- **Comparação visual:** Gráficos que mostram as previsões dos modelos versus os valores reais ao longo do tempo, destacando as regiões de treino, validação e teste.\n",
    "- **Análise de desempenho:** Permite identificar padrões, tendências, possíveis overfits e diferenças de desempenho entre os modelos.\n",
    "\n",
    "> *A avaliação visual é essencial para entender o comportamento dos modelos em diferentes cenários e períodos da série temporal.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54adfe3d",
   "metadata": {},
   "source": [
    "### 6.1. Visualização\n",
    "\n",
    "Os gráficos desta subseção facilitam a análise comparativa entre as previsões dos modelos (MLP, LSTM, GRU) e os valores reais.\n",
    "\n",
    "- **Cores de fundo:** Indicam os splits de treino, validação e teste.\n",
    "- **Linhas:** Representam as previsões suavizadas de cada modelo e os valores reais.\n",
    "- **Divisão em painéis:** Permite visualizar segmentos da série temporal de forma clara e organizada.\n",
    "\n",
    "> *Com esta visualização, é possível identificar rapidamente regiões de bom ou mau desempenho, além de padrões sazonais ou eventos extremos.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77001a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define split colors and model colors ---\n",
    "split_colors = {\n",
    "    \"train\": \"#b39ddb\",  # stronger purple\n",
    "    \"validation\": \"#ffb6b9\",  # stronger pink\n",
    "    \"test\": \"#b2fab4\",  # stronger green\n",
    "}\n",
    "model_colors = {\n",
    "    \"Real\": \"black\",\n",
    "    \"MLP\": \"tab:blue\",\n",
    "    \"LSTM\": \"tab:orange\",\n",
    "    \"GRU\": \"tab:green\",\n",
    "}\n",
    "\n",
    "\n",
    "# --- 2. Recreate chunking and split mapping ---\n",
    "def get_chunk_splits(data, sequence_length=5, min_chunk_size=24, max_chunk_size=100):\n",
    "    n = len(data)\n",
    "    idx = 0\n",
    "    chunk_indices = []\n",
    "    while idx < n:\n",
    "        chunk_size = random.randint(min_chunk_size, max_chunk_size)\n",
    "        if idx + chunk_size >= n:\n",
    "            if n - idx < min_chunk_size:\n",
    "                break\n",
    "            chunk_indices.append((idx, n))\n",
    "            break\n",
    "        else:\n",
    "            chunk_indices.append((idx, idx + chunk_size))\n",
    "            idx += chunk_size\n",
    "\n",
    "    split_map = {}\n",
    "    chunk_boundaries = []\n",
    "    chunk_labels = []\n",
    "    for chunk_id, (start, end) in enumerate(chunk_indices):\n",
    "        chunk_len = end - start\n",
    "        train_end = start + int(chunk_len * 0.6)\n",
    "        val_end = start + int(chunk_len * 0.8)\n",
    "        # Assign split type for each index in chunk\n",
    "        for i in range(start, train_end):\n",
    "            split_map[i] = (\"train\", chunk_id)\n",
    "        for i in range(train_end, val_end):\n",
    "            split_map[i] = (\"validation\", chunk_id)\n",
    "        for i in range(val_end, end):\n",
    "            split_map[i] = (\"test\", chunk_id)\n",
    "        chunk_boundaries.append((start, end))\n",
    "        chunk_labels.append(f\"Chunk {chunk_id}\")\n",
    "    return split_map, chunk_boundaries, chunk_labels\n",
    "\n",
    "\n",
    "split_map, chunk_boundaries, chunk_labels = get_chunk_splits(\n",
    "    df_normalized, sequence_length=5\n",
    ")\n",
    "\n",
    "# --- 3. Prepare data for plotting ---\n",
    "x_labels = df_normalized.index  # Use date or index\n",
    "target_col = \"level_downstream_max\"\n",
    "real_values = df_normalized[target_col].values\n",
    "\n",
    "# --- DENORMALIZE real_values ---\n",
    "cols_to_normalize = [\n",
    "    col for col in df_normalized.columns if col not in [\"date_sin\", \"date_cos\"]\n",
    "]\n",
    "target_idx = df_normalized.columns.get_loc(target_col)\n",
    "dummy = np.zeros((len(real_values), len(cols_to_normalize)))\n",
    "dummy[:, target_idx] = real_values\n",
    "real_values_denorm = scaler.inverse_transform(dummy)[:, target_idx]\n",
    "\n",
    "# For each sample, get split type and chunk id\n",
    "split_types = []\n",
    "chunk_ids = []\n",
    "for i in range(len(df_normalized)):\n",
    "    split, chunk_id = split_map.get(i, (\"none\", -1))\n",
    "    split_types.append(split)\n",
    "    chunk_ids.append(chunk_id)\n",
    "\n",
    "\n",
    "# --- 4. Prediction function for a model ---\n",
    "def get_model_predictions(\n",
    "    model, data, sequence_length, scaler=None, target_col=\"level_downstream_max\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns predictions in the original (unscaled) value for the target column.\n",
    "    scaler: StandardScaler fitted on training data (required for denormalization)\n",
    "    target_col: name of the target column\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    model.eval()\n",
    "    preds = [None] * len(data)\n",
    "    if scaler is None:\n",
    "        from ml.ml_utils import get_scaler\n",
    "\n",
    "        scaler = get_scaler()\n",
    "    cols_to_normalize = [\n",
    "        col for col in data.columns if col not in [\"date_sin\", \"date_cos\"]\n",
    "    ]\n",
    "    target_idx = data.columns.get_loc(target_col)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            x = data.iloc[i : i + sequence_length].values\n",
    "            x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            y_pred_scaled = model(x_tensor).cpu().numpy().squeeze()\n",
    "            # Denormalize prediction\n",
    "            dummy = np.zeros((1, len(cols_to_normalize)))\n",
    "            dummy[0, target_idx] = y_pred_scaled\n",
    "            y_pred_unscaled = scaler.inverse_transform(dummy)[0, target_idx]\n",
    "            preds[i + sequence_length] = y_pred_unscaled\n",
    "    return preds\n",
    "\n",
    "\n",
    "# Set the paths for the best models\n",
    "mlp_checkpoint_path = mlp_optimized_results[\"best_model_path\"]\n",
    "lstm_checkpoint_path = lstm_optimized_results[\"best_model_path\"]\n",
    "gru_checkpoint_path = gru_optimized_results[\"best_model_path\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load best models (replace with your checkpoint paths)\n",
    "mlp_model = MLP.load_from_checkpoint(mlp_checkpoint_path).to(device)\n",
    "lstm_model = LSTM.load_from_checkpoint(lstm_checkpoint_path).to(device)\n",
    "gru_model = GRU.load_from_checkpoint(gru_checkpoint_path).to(device)\n",
    "\n",
    "mlp_preds = get_model_predictions(\n",
    "    mlp_model,\n",
    "    df_normalized,\n",
    "    sequence_length=study_mlp.best_trial.params[\"sequence_length\"],\n",
    ")\n",
    "lstm_preds = get_model_predictions(\n",
    "    lstm_model,\n",
    "    df_normalized,\n",
    "    sequence_length=study_lstm.best_trial.params[\"sequence_length\"],\n",
    ")\n",
    "gru_preds = get_model_predictions(\n",
    "    gru_model,\n",
    "    df_normalized,\n",
    "    sequence_length=study_gru.best_trial.params[\"sequence_length\"],\n",
    ")\n",
    "\n",
    "# --- 5. Plotting with smoothing (split into 4 rows) ---\n",
    "n_splits = 8\n",
    "n_samples = len(real_values_denorm)\n",
    "split_size = n_samples // n_splits\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=n_splits, ncols=1, figsize=(18, 6 * n_splits), sharey=True\n",
    ")\n",
    "\n",
    "window = 7  # Smoothing window size (days/samples)\n",
    "\n",
    "for split_idx in range(n_splits):\n",
    "    ax = axes[split_idx]\n",
    "    start_idx = split_idx * split_size\n",
    "    end_idx = (split_idx + 1) * split_size if split_idx < n_splits - 1 else n_samples\n",
    "\n",
    "    # Get the date indices for this split\n",
    "    split_dates = x_labels[start_idx:end_idx]\n",
    "\n",
    "    # For each sample in this split, shade background according to split type\n",
    "    last_split = None\n",
    "    region_start = 0\n",
    "    for i in range(start_idx, end_idx):\n",
    "        split = split_types[i]\n",
    "        if split != last_split or i == end_idx - 1:\n",
    "            if last_split is not None:\n",
    "                region_end = i if split != last_split else i + 1\n",
    "                color = split_colors.get(last_split, \"#f0f0f0\")\n",
    "                # Use date indices for axvspan\n",
    "                ax.axvspan(\n",
    "                    split_dates[region_start - start_idx],\n",
    "                    (\n",
    "                        split_dates[region_end - start_idx - 1]\n",
    "                        if region_end - start_idx - 1 < len(split_dates)\n",
    "                        else split_dates[-1]\n",
    "                    ),\n",
    "                    color=color,\n",
    "                    alpha=0.25,\n",
    "                    zorder=0,\n",
    "                )\n",
    "            region_start = i\n",
    "            last_split = split\n",
    "\n",
    "    # Smooth real values for this split\n",
    "    real_smooth = (\n",
    "        pd.Series(real_values_denorm[start_idx:end_idx], index=split_dates)\n",
    "        .rolling(window, min_periods=1)\n",
    "        .mean()\n",
    "    )\n",
    "    ax.plot(\n",
    "        split_dates,\n",
    "        real_smooth,\n",
    "        label=\"Real (smoothed)\" if split_idx == 0 else None,\n",
    "        color=model_colors[\"Real\"],\n",
    "        marker=\".\",\n",
    "        markersize=5,\n",
    "        linewidth=1.5,\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # Plot smoothed model predictions (skip None values)\n",
    "    for name, preds, color in [\n",
    "        (\"MLP\", mlp_preds, model_colors[\"MLP\"]),\n",
    "        (\"LSTM\", lstm_preds, model_colors[\"LSTM\"]),\n",
    "        (\"GRU\", gru_preds, model_colors[\"GRU\"]),\n",
    "    ]:\n",
    "        idxs = [i for i in range(start_idx, end_idx) if preds[i] is not None]\n",
    "        vals = [preds[i] for i in idxs]\n",
    "        if vals:\n",
    "            idx_dates = [x_labels[i] for i in idxs]\n",
    "            vals_smooth = (\n",
    "                pd.Series(vals, index=idx_dates).rolling(window, min_periods=1).mean()\n",
    "            )\n",
    "            ax.plot(\n",
    "                idx_dates,\n",
    "                vals_smooth,\n",
    "                label=f\"{name} (smoothed)\" if split_idx == 0 else None,\n",
    "                color=color,\n",
    "                marker=\".\",\n",
    "                markersize=5,\n",
    "                linewidth=1.5,\n",
    "                alpha=0.8,\n",
    "                zorder=3,\n",
    "            )\n",
    "    # X-axis ticks at chunk starts within this split (now using dates)\n",
    "    split_tick_indices = []\n",
    "    split_tick_labels = []\n",
    "    for chunk_start, chunk_end in chunk_boundaries:\n",
    "        # Only consider chunks that overlap with this split\n",
    "        if chunk_end <= start_idx or chunk_start >= end_idx:\n",
    "            continue\n",
    "        chunk_len = chunk_end - chunk_start\n",
    "        train_start = chunk_start\n",
    "        val_start = chunk_start + int(chunk_len * 0.6)\n",
    "        test_start = chunk_start + int(chunk_len * 0.8)\n",
    "        for idx in [train_start, val_start, test_start]:\n",
    "            if start_idx <= idx < end_idx:\n",
    "                split_tick_indices.append(idx)\n",
    "                split_tick_labels.append(str(x_labels[idx].date()))\n",
    "\n",
    "    ax.set_xticks([x_labels[i] for i in split_tick_indices])\n",
    "    ax.set_xticklabels(split_tick_labels, rotation=75)\n",
    "    ax.set_xlabel(f\"Date (Split {split_idx+1})\")\n",
    "    if split_idx == 0:\n",
    "        ax.set_ylabel(target_col)\n",
    "    ax.set_title(\n",
    "        f\"Real vs. Model Predictions (Smoothed) - Split {split_idx+1}/{n_splits}\"\n",
    "    )\n",
    "\n",
    "    # Legends for splits (background) and models (lines) on every subplot\n",
    "    split_patches = [\n",
    "        mpatches.Patch(color=split_colors[k], label=k.capitalize())\n",
    "        for k in split_colors\n",
    "    ]\n",
    "    model_lines = [\n",
    "        plt.Line2D([0], [0], color=model_colors[k], marker=\".\", label=f\"{k} (smoothed)\")\n",
    "        for k in model_colors\n",
    "    ]\n",
    "    ax.legend(handles=split_patches + model_lines, loc=\"upper right\", ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845583bb",
   "metadata": {},
   "source": [
    "## 7. Conclusões\n",
    "\n",
    "*Espaço reservado para as conclusões finais após análise dos resultados dos modelos.*\n",
    "\n",
    "> **Inclua aqui as principais descobertas, limitações e sugestões para trabalhos futuros.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3e7be",
   "metadata": {},
   "source": [
    "\n",
    "*Espaço reservado para métricas quantitativas (RMSE, MAE, etc.) e observações finais após o treinamento dos modelos.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[DEBUG] Columns used for training (df_normalized):\", list(df_normalized.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
